{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dipendensi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'corrections'],\n",
      "        num_rows: 755\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'corrections'],\n",
      "        num_rows: 748\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"jhu-clsp/jfleg\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = data[\"validation\"]\n",
    "test = data[\"test\"]\n",
    "\n",
    "validation_sentence = validation[\"sentence\"]\n",
    "validation_corrections = validation[\"corrections\"]\n",
    "\n",
    "test_sentence = test[\"sentence\"]\n",
    "test_corrections = test[\"corrections\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sentence : \n",
      "1, So I think we can not live if old people could not find siences and tecnologies and they did not developped . \n",
      "2, For not use car . \n",
      "3, Here was no promise of morning except that we looked up through the trees we saw how low the forest had swung . \n",
      "4, Thus even today sex is considered as the least important topic in many parts of India . \n",
      "5, image you salf you are wark in factory just to do one thing like pot taire on car if they fire you you will destroy , becouse u dont know more than pot taire in car . \n",
      "\n",
      "\n",
      "Validation corrections : \n",
      "1. 1. So I think we would not be alive if our ancestors did not develop sciences and technologies . \n",
      "1. 2. So I think we could not live if older people did not develop science and technologies . \n",
      "1. 3. So I think we can not live if old people could not find science and technologies and they did not develop . \n",
      "1. 4. So I think we can not live if old people can not find the science and technology that has not been developed . \n",
      "2. 1. Not for use with a car . \n",
      "2. 2. Do not use in the car . \n",
      "2. 3. Car not for use . \n",
      "2. 4. Can not use the car . \n",
      "3. 1. Here was no promise of morning , except that we looked up through the trees , and we saw how low the forest had swung . \n",
      "3. 2. Here , there was no promise of morning , except that we looked up through the trees and saw how low the forest had swung . \n",
      "3. 3. Here was no promise of morning except that we looked up through the trees and we saw how low the forest had swung . \n",
      "3. 4. There was no promise of morning except when we looked up through the trees and saw how low the forest had swung . \n",
      "4. 1. Thus , even today , sex is considered as the least important topic in may parts of India . \n",
      "4. 2. Thus , even today , sex is considered the least important topic in many parts of India . \n",
      "4. 3. Thus , even today , sex is considered the least important topic in many parts of India . \n",
      "4. 4. Thus , even today sex is considered as the least important topic in many parts of India . \n",
      "5. 1. Imagine yourself you are working in factory just to do one thing like put air a on car if they fire you you will be destroyed , because you do n't know more than to put air a in car . \n",
      "5. 2. Imagine that you work in a factory and do just one thing , like put tires on cars ; if they fire you , they will destroy you because you do n't know how to do anything but put tires on cars . \n",
      "5. 3. image you salf you are wark in factory just to do one thing like pot taire on car if they fire you you will destroy , becouse u dont know more than pot taire in car . \n",
      "5. 4. Imagine yourself working in a factory. You are to do just one thing , such as put a tire on a car. If you are fired , it will destroy you because you do not know how to do more than put tires on cars . \n"
     ]
    }
   ],
   "source": [
    "print(\"Validation sentence : \")\n",
    "for index, val_sen in enumerate(validation_sentence[:5], start=1): \n",
    "    print(f\"{index}, {val_sen}\")\n",
    "print(\"\\n\")\n",
    "print(\"Validation corrections : \")\n",
    "for i, val_cor in enumerate(validation_corrections[:5], start=1): \n",
    "    for j, cor in enumerate(val_cor, start=1):\n",
    "        print (f\"{i}. {j}. {cor}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Pra-pemrosesan Data\n",
    "\n",
    "##### 1.1. Pembersihan Data\n",
    "Data dibersihkan dari karakter yang tidak perlu dibaca, spasi berlebih, dan karakter khusus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    cleaned = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_clean(features):\n",
    "    clean_features = []\n",
    "    for words in features:\n",
    "        clean_features.append(clean_sentence(words))\n",
    "    return clean_features\n",
    "\n",
    "def test_clean(features):\n",
    "    clean_features = []\n",
    "    temp = []\n",
    "    for words_1 in features:\n",
    "        for words_2 in words_1:\n",
    "            temp.append(clean_sentence(words_2))\n",
    "        clean_features.append(temp)\n",
    "        temp = []\n",
    "    return clean_features\n",
    "\n",
    "validation_sentence = validation_clean(validation_sentence)\n",
    "test_sentence = validation_clean(test_sentence)\n",
    "\n",
    "validation_corrections = test_clean(validation_corrections)\n",
    "test_corrections = test_clean(test_corrections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sentence (clean) : \n",
      "1, So I think we can not live if old people could not find siences and tecnologies and they did not developped\n",
      "2, For not use car\n",
      "3, Here was no promise of morning except that we looked up through the trees we saw how low the forest had swung\n",
      "4, Thus even today sex is considered as the least important topic in many parts of India\n",
      "5, image you salf you are wark in factory just to do one thing like pot taire on car if they fire you you will destroy becouse u dont know more than pot taire in car\n",
      "\n",
      "\n",
      "Validation corrections (clean) : \n",
      "1. 1. So I think we would not be alive if our ancestors did not develop sciences and technologies\n",
      "1. 2. So I think we could not live if older people did not develop science and technologies\n",
      "1. 3. So I think we can not live if old people could not find science and technologies and they did not develop\n",
      "1. 4. So I think we can not live if old people can not find the science and technology that has not been developed\n",
      "2. 1. Not for use with a car\n",
      "2. 2. Do not use in the car\n",
      "2. 3. Car not for use\n",
      "2. 4. Can not use the car\n",
      "3. 1. Here was no promise of morning except that we looked up through the trees and we saw how low the forest had swung\n",
      "3. 2. Here there was no promise of morning except that we looked up through the trees and saw how low the forest had swung\n",
      "3. 3. Here was no promise of morning except that we looked up through the trees and we saw how low the forest had swung\n",
      "3. 4. There was no promise of morning except when we looked up through the trees and saw how low the forest had swung\n",
      "4. 1. Thus even today sex is considered as the least important topic in may parts of India\n",
      "4. 2. Thus even today sex is considered the least important topic in many parts of India\n",
      "4. 3. Thus even today sex is considered the least important topic in many parts of India\n",
      "4. 4. Thus even today sex is considered as the least important topic in many parts of India\n",
      "5. 1. Imagine yourself you are working in factory just to do one thing like put air a on car if they fire you you will be destroyed because you do nt know more than to put air a in car\n",
      "5. 2. Imagine that you work in a factory and do just one thing like put tires on cars if they fire you they will destroy you because you do nt know how to do anything but put tires on cars\n",
      "5. 3. image you salf you are wark in factory just to do one thing like pot taire on car if they fire you you will destroy becouse u dont know more than pot taire in car\n",
      "5. 4. Imagine yourself working in a factory You are to do just one thing such as put a tire on a car If you are fired it will destroy you because you do not know how to do more than put tires on cars\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation sentence (clean) : \")\n",
    "for index, val_sen in enumerate(validation_sentence[:5], start=1): \n",
    "    print(f\"{index}, {val_sen}\")\n",
    "print(\"\\n\")\n",
    "print(\"Validation corrections (clean) : \")\n",
    "for i, val_cor in enumerate(validation_corrections[:5], start=1): \n",
    "    for j, cor in enumerate(val_cor, start=1):\n",
    "        print (f\"{i}. {j}. {cor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2. Normalisasi Data\n",
    "Data diubah menjadi huruf kecil dan dikonversikan semua kata menjadi bentuk dasar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aditt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\aditt\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_sentence(sentence):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sentence = sentence.lower()\n",
    "    kata = sentence.split()\n",
    "    kata_dasar = [lemmatizer.lemmatize(k) for k in kata]\n",
    "    return ' '.join(kata_dasar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_lemmatize(features):\n",
    "    lemmatize_features = []\n",
    "    for words in features:\n",
    "        lemmatize_features.append(lemmatize_sentence(words))\n",
    "    return lemmatize_features\n",
    "\n",
    "def test_lemmatize(features):\n",
    "    lemmatize_features = []\n",
    "    temp = []\n",
    "    for words_1 in features:\n",
    "        for words_2 in words_1:\n",
    "            temp.append(lemmatize_sentence(words_2))\n",
    "        lemmatize_features.append(temp)\n",
    "        temp = []\n",
    "    return lemmatize_features\n",
    "\n",
    "validation_sentence = validation_lemmatize(validation_sentence)\n",
    "test_sentence = validation_lemmatize(test_sentence)\n",
    "\n",
    "validation_corrections = test_lemmatize(validation_corrections)\n",
    "test_corrections = test_lemmatize(test_corrections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sentence (lemmatize) : \n",
      "1, so i think we can not live if old people could not find siences and tecnologies and they did not developped\n",
      "2, for not use car\n",
      "3, here wa no promise of morning except that we looked up through the tree we saw how low the forest had swung\n",
      "4, thus even today sex is considered a the least important topic in many part of india\n",
      "5, image you salf you are wark in factory just to do one thing like pot taire on car if they fire you you will destroy becouse u dont know more than pot taire in car\n",
      "\n",
      "\n",
      "Validation corrections (lemmatize) : \n",
      "1. 1. so i think we would not be alive if our ancestor did not develop science and technology\n",
      "1. 2. so i think we could not live if older people did not develop science and technology\n",
      "1. 3. so i think we can not live if old people could not find science and technology and they did not develop\n",
      "1. 4. so i think we can not live if old people can not find the science and technology that ha not been developed\n",
      "2. 1. not for use with a car\n",
      "2. 2. do not use in the car\n",
      "2. 3. car not for use\n",
      "2. 4. can not use the car\n",
      "3. 1. here wa no promise of morning except that we looked up through the tree and we saw how low the forest had swung\n",
      "3. 2. here there wa no promise of morning except that we looked up through the tree and saw how low the forest had swung\n",
      "3. 3. here wa no promise of morning except that we looked up through the tree and we saw how low the forest had swung\n",
      "3. 4. there wa no promise of morning except when we looked up through the tree and saw how low the forest had swung\n",
      "4. 1. thus even today sex is considered a the least important topic in may part of india\n",
      "4. 2. thus even today sex is considered the least important topic in many part of india\n",
      "4. 3. thus even today sex is considered the least important topic in many part of india\n",
      "4. 4. thus even today sex is considered a the least important topic in many part of india\n",
      "5. 1. imagine yourself you are working in factory just to do one thing like put air a on car if they fire you you will be destroyed because you do nt know more than to put air a in car\n",
      "5. 2. imagine that you work in a factory and do just one thing like put tire on car if they fire you they will destroy you because you do nt know how to do anything but put tire on car\n",
      "5. 3. image you salf you are wark in factory just to do one thing like pot taire on car if they fire you you will destroy becouse u dont know more than pot taire in car\n",
      "5. 4. imagine yourself working in a factory you are to do just one thing such a put a tire on a car if you are fired it will destroy you because you do not know how to do more than put tire on car\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation sentence (lemmatize) : \")\n",
    "for index, val_sen in enumerate(validation_sentence[:5], start=1): \n",
    "    print(f\"{index}, {val_sen}\")\n",
    "print(\"\\n\")\n",
    "print(\"Validation corrections (lemmatize) : \")\n",
    "for i, val_cor in enumerate(validation_corrections[:5], start=1): \n",
    "    for j, cor in enumerate(val_cor, start=1):\n",
    "        print (f\"{i}. {j}. {cor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3. Tokenisasi\n",
    "Dilakukan tokenisasi kepada data dengan memecah kalimat ke dalam per-kata, dan dilakukan pemberian id khusus per-kata\n",
    "khusus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aditt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buat_indeks_kata(list_kata):\n",
    "    kata_unik = list(set(list_kata))\n",
    "    indeks_kata = {kata: idx + 1 for idx, kata in enumerate(kata_unik)}\n",
    "    return indeks_kata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
